{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import goPhishing\n",
    "\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function #enforces python 3 syntax\n",
    "import httplib2\n",
    "from bs4 import BeautifulSoup, SoupStrainer\n",
    "from urllib.parse import urlparse\n",
    "import urllib\n",
    "import requests\n",
    "import csv\n",
    "import os\n",
    "import time\n",
    "import whois\n",
    "import regex\n",
    "import re\n",
    "import xml.etree.ElementTree\n",
    "from datetime import datetime\n",
    "import dateutil.parser\n",
    "from io import StringIO as io\n",
    "import sys\n",
    "import dryscrape\n",
    "from random import shuffle\n",
    "import tldextract\n",
    "import socket\n",
    "socket.setdefaulttimeout(10) # or whatever timeout you want"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    def abnormalUrl(self):\n",
    "        '''Fixed to use WHOIS from within Python to match parsed data from actual URL'''\n",
    "        # Trying a different approach through the use of socket.\n",
    "        parsed_uri = urlparse(self.url)\n",
    "        domainURL = '{uri.netloc}'.format(uri=parsed_uri)\n",
    "        ip = socket.gethostbyname(domainURL)\n",
    "        domain = socket.gethostbyaddr(ip)[0]\n",
    "\n",
    "\n",
    "        try:\n",
    "            if not re.search(domain,url):\n",
    "                retVal =1\n",
    "            else:\n",
    "                retVal =-1\n",
    "        except:\n",
    "            printFormat (\"exc\",\"abnormalUrl\" , \"Unknown Error\")\n",
    "        self.phishScore['abnormalUrl'] = retVal\n",
    "        return retVal\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'http://www.pisqr.net/pisqr/www.loginalibaba.com/alibaba/alibaba/login.alibaba.com.php?email=abuse@riela.com%5Cr%5Cn'\n",
    "#abnormalUrl(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parsed_uri = urlparse(url)\n",
    "print(parsed_uri)\n",
    "# Find domain from URL to search WHOIS\n",
    "domainURL = '{uri.netloc}'.format(uri=parsed_uri)\n",
    "print(domainURL)\n",
    "# WHOIS query to pull name.\n",
    "#c = whois.query(domainURL)\n",
    "#domain = c.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipwhois\n",
    "import socket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(url)\n",
    "parsed_uri = urlparse(url)\n",
    "domainURL = '{uri.netloc}'.format(uri=parsed_uri)\n",
    "print(domainURL)\n",
    "ip = socket.gethostbyname(domainURL)\n",
    "print(ip)\n",
    "domain = socket.gethostbyaddr(ip)[0]\n",
    "print(domain)\n",
    "ipwhodis = ipwhois.IPWhois(ip)\n",
    "results = ipwhodis.lookup_whois()\n",
    "\n",
    "#print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = ipwhodis.lookup_whois(url)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(results)\n",
    "\n",
    "for item in results['nets']:\n",
    "    print(item['updated'])\n",
    "    print(item)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# url = whois.query(self.split(\"//\")[-1].split(\"/\")[0].split('?')[0])\n",
    "# createDate = url.creation_date\n",
    "# print(createDate)\n",
    "\n",
    "parsed_uri = urlparse(url)\n",
    "# grab domain\n",
    "domainURL = '{uri.netloc}'.format(uri=parsed_uri)\n",
    "ip = socket.gethostbyname(domainURL)\n",
    "# domain = socket.gethostbyaddr(ip)[0]\n",
    "# print(domain)\n",
    "\n",
    "ipwhodis = ipwhois.IPWhois(ip)\n",
    "results = ipwhodis.lookup_whois()\n",
    "for item in results['nets']:\n",
    "    createdDate = item['created']\n",
    "createDate = datetime.strptime(createdDate, '%Y-%m-%d')\n",
    "currentDate = datetime.now()\n",
    "dateDiff = currentDate-createDate\n",
    "dateDiffInYears = (dateDiff.days + dateDiff.seconds/86400)/365.2425\n",
    "print(\"diff in years: \",dateDiffInYears)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'http://www.zlookup.com/'\n",
    "parsed_uri = urlparse(url)\n",
    "print(parsed_uri)\n",
    "domainURL = '{uri.netloc}'.format(uri=parsed_uri)\n",
    "print(domainURL)\n",
    "ip = socket.gethostbyname(domainURL)\n",
    "print(ip)\n",
    "ipwhodis = ipwhois.IPWhois(ip)\n",
    "results = ipwhodis.lookup_rdap()\n",
    "# for key, values in results.items():\n",
    "#     print(key, values)\n",
    "\n",
    "# Open cmd to run whois query.\n",
    "# command = 'whois ' + domainURL\n",
    "#print(command)\n",
    "# resultant = str(os.popen(command).read())\n",
    "# print(resultant)\n",
    "#print(results)\n",
    "try:\n",
    "    domain = socket.gethostbyaddr(ip)\n",
    "except:\n",
    "    print('domain is invalid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def abnormalUrl(url):\n",
    "    '''Fixed to use WHOIS from within Python to match parsed data from actual URL'''\n",
    "    # Trying a different approach through the use of socket.\n",
    "    retVal = 0\n",
    "    try:\n",
    "        parsed_uri = urlparse(url)\n",
    "        try:        \n",
    "            domainURL = '{uri.netloc}'.format(uri=parsed_uri)\n",
    "            ip = socket.gethostbyname(domainURL)\n",
    "            domain = socket.gethostbyaddr(ip)[0]\n",
    "        except:\n",
    "            print('invalid hostname...')\n",
    "            retVal = 0\n",
    "            return retVal\n",
    "        if not re.search(domain,url):\n",
    "            retVal = 1\n",
    "        else:\n",
    "            retVal = -1\n",
    "    except:\n",
    "        print (\"exc\", \"abnormalUrl\", \"Unknown Error\")\n",
    "    #self.phishScore['abnormalUrl'] = retVal\n",
    "    return retVal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abnormalUrl(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "# Create header rows from dataset that was processed by goPhishing.py.\n",
    "\n",
    "newStr = ['havingIPAddress','urlLength','havingAtSymbol','doubleSlashRedirecting','prefixSuffix'\n",
    "          ,'havingSubDomain','sslFinalState','domainRegistrationLength','favicon','port'\n",
    "          ,'httpsToken','requestURL','urlOfAnchor','linksInTags','sfh','submittingToEmail',\n",
    "          'abnormalURL','redirect','onMouseOver','rightClick',\n",
    "          'popUpWindow','iFrame','ageOfDomain','dnsRecord','webTraffic',\n",
    "          ,'linksPointingToPage','statisticalReport']\n",
    "\n",
    "import csv\n",
    "with open('results_alexa.csv',newline='') as f:\n",
    "    r = csv.reader(f)\n",
    "    data = [line for line in r]\n",
    "with open('results_alexa.csv','w',newline='') as f:\n",
    "    w = csv.writer(f)\n",
    "    w.writerow(newStr)\n",
    "    w.writerows(data)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Import section'''\n",
    "\n",
    "from __future__ import print_function\n",
    "from __future__ import absolute_import\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import tree\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Later used for labeling tree data output. \n",
    "\n",
    "uci = pd.read_csv('results_openfish.csv')\n",
    "\n",
    "uci.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = np.genfromtxt('results_openfish.csv',delimiter=',',dtype=np.int32)\n",
    "\n",
    "print(uci.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split data into x(features) and y(label)\n",
    "inputs = training_data[:,:-1]\n",
    "outputs = training_data[:,-1]\n",
    "\n",
    "\n",
    "#split data by 20%\n",
    "x_train ,x_test,y_train, y_test = train_test_split(inputs,outputs,test_size=0.3)       #test_size=0.2(whole_data)\n",
    "\n",
    "print(len(x_test))\n",
    "print(len(x_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgr_test = LogisticRegression()\n",
    "\n",
    "lgr_test.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = lgr_test.predict(x_test)\n",
    "\n",
    "accuracy = 100.0 * accuracy_score(y_test, predictions)\n",
    "\n",
    "print (\"The accuracy of your Logistic Regression on testing data is: \" + str(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ats\n",
    "from datetime import datetime\n",
    "\n",
    "ak= 'AKIAIJJJWOX73BM2QTTQ'\n",
    "sk= 'd0T6LBAUsqFevPqN2Fz8BXu4MmXtElxvHue5o1au'\n",
    "time_stamp = datetime.utcnow().strftime(\"%Y%m%dT%H%M%SZ\")\n",
    "date_stamp = datetime.utcnow().strftime(\"%Y%m%d\")\n",
    "\n",
    "ats.AlexaTopSites(ak,sk).get_sites('1','10000','US',time_stamp, date_stamp)\n",
    "\n",
    "\n",
    "# with open ('top_alexa.json') as a:\n",
    "#     text = a.read().splitlines()\n",
    "#     for line in text:\n",
    "#         if \n",
    "   \n",
    "\n",
    "\n",
    "#ats.main()\n",
    "# -key ak, -secret sk, -country US, -count 100\n",
    "#os.system('python3 ats.py')\n",
    "print(type(topsites))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "listing = []\n",
    "with open('top_alexa.json') as data_file:    \n",
    "    data = json.load(data_file)\n",
    "    for v in data.values():\n",
    "        url = 'http://www.' + str(v)\n",
    "        listing.append(url)\n",
    "        \n",
    "with open('top_sites.txt', 'w+') as f:\n",
    "    for item in listing:\n",
    "        f.write(item + '\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(listing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipwhois\n",
    "import re\n",
    "\n",
    "def getageOfDomain(self):\n",
    "    \"\"\"Get age of domain. If it is less than 10 years old, it returns 0\"\"\"\n",
    "    # This one is working...\n",
    "    retVal = 0\n",
    "    try:\n",
    "        parsed_uri = urlparse(self)\n",
    "        domainURL = '{uri.netloc}'.format(uri=parsed_uri)\n",
    "        ip = socket.gethostbyname(domainURL)\n",
    "        ipwhodis = ipwhois.IPWhois(ip)\n",
    "        results = ipwhodis.lookup_whois()\n",
    "        for item in results['nets']:\n",
    "            createdDate = item['created']\n",
    "        createdDate = item['created']\n",
    "        match = re.search(r'\\d{4}-\\d{2}-\\d{2}', createdDate)\n",
    "        createDate = datetime.strptime(match.group(), '%Y-%m-%d').date()\n",
    "        #createDate = datetime.strftime(date, '%Y-%m-%d')\n",
    "        currentDate = datetime.now().date()\n",
    "        dateDiff = currentDate - createDate\n",
    "        dateDiffInYears = (dateDiff.days + dateDiff.seconds/86400)/365.2425\n",
    "        # print(\"diff in years: \",dateDiffInYears)\n",
    "        if dateDiffInYears >= 10:\n",
    "            retVal = 1\n",
    "        else:\n",
    "            retVal = -1\n",
    "    except:\n",
    "        printFormat(\"exc\", \"getageOfDomain\", \"Unknown Error\" )\n",
    "    self.phishScore['getageOfDomain'] = retVal\n",
    "    return retVal\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = 0\n",
    "testURLs = []\n",
    "with open('openfish.txt') as f:\n",
    "    for item in f:\n",
    "        \n",
    "        if counter < 25:\n",
    "            testURLs.append(item)\n",
    "            getageOfDomain(item)\n",
    "            counter += 1\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "for url in testURLs:\n",
    "    parsed_uri = urlparse(url)\n",
    "    #print('parsed:  ' + str(parsed_uri))\n",
    "    domainURL = '{uri.netloc}'.format(uri=parsed_uri)\n",
    "    #print('domainURL = '+ str(domainURL))\n",
    "    ip = socket.gethostbyname(domainURL)\n",
    "    #print(ip)\n",
    "    ipwhodis = ipwhois.IPWhois(ip)\n",
    "    results = ipwhodis.lookup_whois()\n",
    "    #print('results*** '+ str(results))\n",
    "    for item in results['nets']:\n",
    "        try:\n",
    "            createdDate = item['created']\n",
    "            match = re.search(r'\\d{4}-\\d{2}-\\d{2}', createdDate)\n",
    "            createDate = datetime.strptime(match.group(), '%Y-%m-%d').date()\n",
    "            #createDate = datetime.strftime(date, '%Y-%m-%d')\n",
    "            currentDate = datetime.now().date()\n",
    "            dateDiff = currentDate - createDate\n",
    "            dateDiffInYears = (dateDiff.days + dateDiff.seconds/86400)/365.2425\n",
    "            print(dateDiffInYears)\n",
    "        except:\n",
    "            print('Found an error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retVal = 0\n",
    "for url in testURLs:\n",
    "    parsed_uri = urlparse(url)\n",
    "    domainURL = '{uri.netloc}'.format(uri=parsed_uri)\n",
    "    ip = socket.gethostbyname(domainURL)\n",
    "    ipwhodis = ipwhois.IPWhois(ip)\n",
    "    results = ipwhodis.lookup_whois()\n",
    "    for item in results['nets']:\n",
    "        createdDate = item['created']\n",
    "    \n",
    "    match = re.search(r'\\d{4}-\\d{2}-\\d{2}', createdDate)\n",
    "    date = datetime.strptime(match.group(), '%Y-%m-%d').date()\n",
    "    \n",
    "    currentDate = datetime.now().date()\n",
    "    dateDiff = currentDate - date\n",
    "    dateDiffInYears = (dateDiff.days + dateDiff.seconds/86400)/365.2425\n",
    "    # print(\"diff in years: \",dateDiffInYears)\n",
    "    if dateDiffInYears >= 10:\n",
    "        retVal = 1\n",
    "    else:\n",
    "        retVal = -1\n",
    "    \n",
    "print(retVal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def abnormalUrl(self):\n",
    "    '''Fixed to use WHOIS from within Python to match parsed data from actual URL'''\n",
    "    # Trying a different approach through the use of socket.\n",
    "    retVal = 0\n",
    "    try:\n",
    "        parsed_uri = urlparse(self)\n",
    "\n",
    "        domainURL = '{uri.netloc}'.format(uri=parsed_uri)\n",
    "        ip = socket.gethostbyname(domainURL)\n",
    "        try:\n",
    "            domain = socket.gethostbyaddr(ip)[0]\n",
    "        except:\n",
    "            retVal = -1\n",
    "            print('***Invalid hostname***')\n",
    "            return print(retVal)\n",
    "        if not re.search(domain,self):\n",
    "            retVal = 1\n",
    "        else:\n",
    "            retVal = -1\n",
    "    except:\n",
    "        print(\"exc\", \"abnormalUrl\", \"Unknown Error\")\n",
    "    #self.phishScore['abnormalUrl'] = retVal\n",
    "    return print(retVal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = 0\n",
    "testURLs = []\n",
    "with open('openfish.txt') as f:\n",
    "    for item in f:\n",
    "        \n",
    "        if counter < 25:\n",
    "            testURLs.append(item)\n",
    "            #abnormalUrl(item)\n",
    "            counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "www.pisqr.net 198.187.31.3 server259-41.web-hosting.com\n",
      "www.globaltradingacademy.org 160.153.129.29 ip-160-153-129-29.ip.secureserver.net\n",
      "alshaheensecurity.com 5.9.87.48 static.48.87.9.5.clients.your-server.de\n",
      "alshaheensecurity.com 5.9.87.48 static.48.87.9.5.clients.your-server.de\n",
      "akwaabait.com 69.65.3.197 server407.webhostingpad.com\n"
     ]
    },
    {
     "ename": "herror",
     "evalue": "[Errno 1] Unknown host",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mherror\u001b[0m                                    Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-14e225dce795>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mdomainURL\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'{uri.netloc}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muri\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparsed_uri\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mip\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgethostbyname\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdomainURL\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mdomain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgethostbyaddr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mip\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdomainURL\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mip\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdomain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mherror\u001b[0m: [Errno 1] Unknown host"
     ]
    }
   ],
   "source": [
    "for url in testURLs:\n",
    "    parsed_uri = urlparse(url)\n",
    "    domainURL = '{uri.netloc}'.format(uri=parsed_uri)\n",
    "    ip = socket.gethostbyname(domainURL)\n",
    "    domain = socket.gethostbyaddr(ip)[0]\n",
    "    print(domainURL, ip, domain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error in attrs\n",
      "{'name': 'imp_login', 'action': 'portal.swisscom.ch.php', 'method': 'post', 'target': '_parent'}\n",
      "404 not found\n",
      "404 not found\n",
      "{'accept-charset': ['UTF-8'], 'action': 'other.php', 'autocomplete': 'off', 'id': 'login', 'method': 'post', 'name': 'login'}\n",
      "404 not found\n",
      "404 not found\n",
      "404 not found\n",
      "error in attrs\n",
      "404 not found\n",
      "404 not found\n",
      "404 not found\n",
      "404 not found\n",
      "404 not found\n",
      "404 not found\n",
      "404 not found\n",
      "{'action': 'https://www.huntington.com/search', 'method': 'GET', 'target': '_blank'}\n",
      "{'action': 'https://www.huntington.com/search', 'method': 'GET', 'target': '_blank'}\n",
      "{'class': ['search'], 'id': 'header-search', 'method': 'get', 'name': 'searchForm', 'autocomplete': 'off', 'action': 'https://www.huntington.com/search', 'data-intelliresponse': '', 'data-isuggest-interface-id': '2'}\n",
      "{'method': 'post', 'action': 'post.php'}\n",
      "{'method': 'POST', 'id': 'loginForm', 'action': 'done.php'}\n",
      "404 not found\n",
      "error in attrs\n",
      "{'id': 'login-form', 'name': 'login-form', 'method': 'post', 'action': '../redirect.php', 'class': ['form', 'clr', 'style-type-auto', 'lang-en_us', 'auto-en_us', '']}\n",
      "404 not found\n"
     ]
    }
   ],
   "source": [
    "for url in testURLs:\n",
    "    try:\n",
    "        page = urllib.request.urlopen(url)\n",
    "        parsed_html = BeautifulSoup(page, features='lxml') \n",
    "        try:\n",
    "            parseList = parsed_html.body.find('form').attrs\n",
    "            print(parseList)\n",
    "        except:\n",
    "            print('error in attrs')\n",
    "    except:\n",
    "        print('404 not found')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def havingIP(self):\n",
    "    # This one is working.\n",
    "    retVal = -1\n",
    "    try:\n",
    "        parsed_uri = urlparse(self.url)\n",
    "        domain = '{uri.netloc}'.format(uri=parsed_uri)\n",
    "        checkIP = re.match(r\"^\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}$\", self)\n",
    "        if checkIP:\n",
    "            retVal = 1\n",
    "        else:\n",
    "            print('No IP in URL.')\n",
    "            return retVal\n",
    "    except:\n",
    "        printFormat(\"exc\", \"havingIP\", \"Unknown Error\")\n",
    "    self.phishScore['havingIP'] = retVal\n",
    "    return retVal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No IP in URL.\n",
      "-1\n",
      "No IP in URL.\n",
      "-1\n",
      "No IP in URL.\n",
      "-1\n",
      "No IP in URL.\n",
      "-1\n",
      "No IP in URL.\n",
      "-1\n",
      "No IP in URL.\n",
      "-1\n",
      "No IP in URL.\n",
      "-1\n",
      "No IP in URL.\n",
      "-1\n",
      "No IP in URL.\n",
      "-1\n",
      "No IP in URL.\n",
      "-1\n",
      "No IP in URL.\n",
      "-1\n",
      "No IP in URL.\n",
      "-1\n",
      "No IP in URL.\n",
      "-1\n",
      "No IP in URL.\n",
      "-1\n",
      "No IP in URL.\n",
      "-1\n",
      "15\n"
     ]
    }
   ],
   "source": [
    "counter = 0\n",
    "testURLs = []\n",
    "with open('openfish.txt') as f:\n",
    "    for item in f:\n",
    "        \n",
    "        if counter < 15:\n",
    "            testURLs.append(item)\n",
    "            print(havingIP(item))\n",
    "            counter += 1\n",
    "print(counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def onMouseOver(self):\n",
    "    \"\"\"\n",
    "    This method looks for the on mouse over re-writing of links in the status bar.  \n",
    "    This type of ruse has become less effective as browsers usually ignore this.\n",
    "    \"\"\"\n",
    "    # This one is working however may be useless and outdated in usage. Will utilize until tested. \n",
    "    retVal = 0\n",
    "    try:\n",
    "        page = urllib.request.urlopen(self)\n",
    "        parsed_html = BeautifulSoup(page, features='lxml') \n",
    "        parseList = parsed_html.body.find('a').attrs\n",
    "        #print(parseList)\n",
    "        for key, values in parseList.items():\n",
    "            #print(key, values)\n",
    "            if key == 'onmouseover':\n",
    "                match = re.search(r'window.status',tag['onmouseover'])\n",
    "                if match:\n",
    "                    retVal = 1\n",
    "                else:\n",
    "                    retVal = -1\n",
    "            if key == 'href':  #matches the href=javascript tag\n",
    "                hrefMatch = re.search(r'javascript',tag['href'])\n",
    "                if hrefMatch:\n",
    "                    retVal = 1\n",
    "                else:\n",
    "                    retVal = -1\n",
    "    except:\n",
    "        print(\"exc\", \"onMouseOver\", \"On mouse over exception\")\n",
    "    #self.phishScore['onMouseOver'] = retVal\n",
    "    return retVal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exc onMouseOver On mouse over exception\n",
      "0\n",
      "0\n",
      "exc onMouseOver On mouse over exception\n",
      "0\n",
      "exc onMouseOver On mouse over exception\n",
      "0\n",
      "exc onMouseOver On mouse over exception\n",
      "0\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "counter = 0\n",
    "#testURLs = []\n",
    "with open('openfish.txt') as f:\n",
    "    for item in f:\n",
    "        \n",
    "        if counter < 5:\n",
    "            #testURLs.append(item)\n",
    "            print(onMouseOver(item))\n",
    "            counter += 1\n",
    "print(counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No connection...\n",
      "No connection...\n",
      "No connection...\n"
     ]
    }
   ],
   "source": [
    "for url in testURLs:\n",
    "    try:\n",
    "        page = urllib.request.urlopen(url)\n",
    "#         parsed_html = BeautifulSoup(page, features='lxml') \n",
    "#         parseList = parsed_html.body.find('a').attrs\n",
    "        \n",
    "    except:\n",
    "        print('No connection...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hasNonStandardPort(self):\n",
    "    '''May end up changing this just to check for port usage.'''\n",
    "    retVal = 0\n",
    "    try:\n",
    "        parsed_uri = urllib.parse.urlparse(self.url)\n",
    "        print(parsed_uri.port)\n",
    "        if (parsed_uri.port == None or  parsed_uri.port == 80 or parsed_uri.port == 443):\n",
    "            print('Parsed uri.port is: ' + str(parsed_uri.port))\n",
    "            retVal = -1\n",
    "        else:\n",
    "            retVal =1\n",
    "    except:\n",
    "        print(\"exc\", \"hasNonStandardPort\", \"Unknown Error\")\n",
    "\n",
    "    self.phishScore['port'] = retVal\n",
    "    return retVal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "for url in testURLs:\n",
    "    print(urllib.parse.urlparse(url).port)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://www.google.com\n",
      "\n"
     ]
    },
    {
     "ename": "ServerNotFoundError",
     "evalue": "Unable to find the server at www.google.com\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mgaierror\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/httplib2/__init__.py\u001b[0m in \u001b[0;36m_conn_request\u001b[0;34m(self, conn, request_uri, method, body, headers)\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msock\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1501\u001b[0;31m                     \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m                 \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest_uri\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/httplib2/__init__.py\u001b[0m in \u001b[0;36mconnect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1143\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mres\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetaddrinfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhost\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mport\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSOCK_STREAM\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1144\u001b[0m             \u001b[0maf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msocktype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproto\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcanonname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msa\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/socket.py\u001b[0m in \u001b[0;36mgetaddrinfo\u001b[0;34m(host, port, family, type, proto, flags)\u001b[0m\n\u001b[1;32m    747\u001b[0m     \u001b[0maddrlist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 748\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mres\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_socket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetaddrinfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhost\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mport\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfamily\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproto\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    749\u001b[0m         \u001b[0maf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msocktype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproto\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcanonname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msa\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mgaierror\u001b[0m: [Errno 8] nodename nor servname provided, or not known",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mServerNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-47-86aa3cb5972c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mhttp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhttplib2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mHttp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhttp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m         \u001b[0;31m#print('{} is the url and the status is: {}'.format(url, status))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/httplib2/__init__.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, uri, method, body, headers, redirections, connection_type)\u001b[0m\n\u001b[1;32m   1922\u001b[0m                         \u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1923\u001b[0m                         \u001b[0mredirections\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1924\u001b[0;31m                         \u001b[0mcachekey\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1925\u001b[0m                     )\n\u001b[1;32m   1926\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/httplib2/__init__.py\u001b[0m in \u001b[0;36m_request\u001b[0;34m(self, conn, host, absolute_uri, request_uri, method, body, headers, redirections, cachekey)\u001b[0m\n\u001b[1;32m   1593\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1594\u001b[0m         (response, content) = self._conn_request(\n\u001b[0;32m-> 1595\u001b[0;31m             \u001b[0mconn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest_uri\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1596\u001b[0m         )\n\u001b[1;32m   1597\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/httplib2/__init__.py\u001b[0m in \u001b[0;36m_conn_request\u001b[0;34m(self, conn, request_uri, method, body, headers)\u001b[0m\n\u001b[1;32m   1506\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgaierror\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1507\u001b[0m                 \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1508\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mServerNotFoundError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Unable to find the server at %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhost\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1509\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1510\u001b[0m                 errno_ = (\n",
      "\u001b[0;31mServerNotFoundError\u001b[0m: Unable to find the server at www.google.com\n"
     ]
    }
   ],
   "source": [
    "with open('top_sites.txt') as f:\n",
    "    \n",
    "    for url in f:\n",
    "        print(url)\n",
    "        http = httplib2.Http()\n",
    "        status, response = http.request(url)\n",
    "        #print('{} is the url and the status is: {}'.format(url, status))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "newStr = ['havingIPAddress','urlLength','havingAtSymbol','doubleSlashRedirecting','prefixSuffix'\n",
    "          ,'havingSubDomain','sslFinalState','domainRegistrationLength','favicon','port'\n",
    "          ,'httpsToken','requestURL','urlOfAnchor','linksInTags','sfh','submittingToEmail'\n",
    "          ,'abnormalURL','redirect','onMouseOver','rightClick'\n",
    "          ,'popUpWindow','iFrame','ageOfDomain','dnsRecord','webTraffic'\n",
    "          ,'linksPointingToPage','statisticalReport']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(newStr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
